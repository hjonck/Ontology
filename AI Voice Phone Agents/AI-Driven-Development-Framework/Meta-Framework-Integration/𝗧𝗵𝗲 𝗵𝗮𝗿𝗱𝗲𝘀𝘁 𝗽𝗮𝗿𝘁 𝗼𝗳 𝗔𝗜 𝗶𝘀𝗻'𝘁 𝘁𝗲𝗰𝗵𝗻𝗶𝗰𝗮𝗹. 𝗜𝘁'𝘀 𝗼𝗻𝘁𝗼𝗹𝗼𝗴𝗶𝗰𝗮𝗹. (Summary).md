
# The hardest part of AI isn't technical. It's ontological.

> Your current stack is built on a half-truth: that data is just data. AI needs context, pretext, and subtext. It needs to know not just what something is, but why it exists and how it relates to everything else.

**The uncomfortable truth:** Most organisations have their intelligence in all the wrong places. It's trapped in Janet's head, coded into Brad's macros, buried in footnotes of quarterly reports.

**You can’t simply layer intelligence on top of disconnected systems.** You need to push semantic awareness down to the atomic level. Every data point needs to carry its own context. Every field needs to know its purpose. Every connection needs to understand its significance.

---

**This isn't about cleaning your data. It's about teaching it to think.**

> While Traditional development looks something like this: Data → Logic → Interface  
> AI-native development needs to flow like so: Meaning → Relationships → Emergence

| Traditional development | AI-native development |
| ----------------------- | --------------------- |
| Data → Logic → Interface | Meaning → Relationships → Emergence |

When metadata becomes "meta-cognition"—when your systems understand not just what they store but what it means—that's when AI stops being a tool and starts being transformative.

The organizations winning with AI? They're not the ones with the best models. They're the ones who rebuilt their entire information architecture around meaning, not just measurement.

*Is your data smart enough for AI to be brilliant?*

---

Stay tuned, next week, Hardy Jonck, CEO of Agileworks Group, will be sharing insights and answering questions about our in-house AI development

#AITransformation #DataArchitecture #EnterpriseAI #DigitalStrategy

---

## Questions that could be posed for post 2:

In our previous post, we spoke about AI readiness, and how implementing it goes far beyond plugging in a model. [link] Today, we’re digging deeper into what it really takes to build AI-ready architecture, with Hardy Jonck, CEO of Agileworks Group who was asked some of his favorite questions 🙂.

- How is AW implementing AI in their system?  
- What is the biggest challenge you have had to overcome?  
- What benefit do you hope to reap from this integration?  
- What does it look like when a system understands why a piece of data exists—not just what it is?  
- How can a company tell if its current stack is built on the “half-truth” of data being just data? What are the signs?  
- You contrast traditional development with AI-native development. How should teams shift their thinking when approaching AI-first architecture?  
- Do you think most companies will ever be ready for AI that’s truly intelligent—or will we always be retrofitting meaning onto legacy systems?  

**Got a question for Hardy? Drop us a message; we’re always keen to continue the conversation.**

*This was for a linked article*

In our previous post, we discussed AI readiness and how implementing it goes far beyond plugging in a model. https://www.linkedin.com/posts/agileworks-group\_aitransformation-dataarchitecture-enterpriseai-activity-7341370955950129152-7-Uu?utm\_source=share\&utm\_medium=member\_desktop\&rcm=ACoAACn61MIB9DAYfgUG-CKtnnA0onxMZA6jSw8

Today, we’re digging deeper into what it really takes to build AI-ready architecture, with Hardy Jonck, CEO of Agileworks Group, who was asked some of his favourite questions 🙂.

* 𝗛𝗼𝘄 𝗶𝘀 𝗔𝗴𝗶𝗹𝗲𝘄𝗼𝗿𝗸𝘀 𝗚𝗿𝗼𝘂𝗽 𝗶𝗺𝗽𝗹𝗲𝗺𝗲𝗻𝘁𝗶𝗻𝗴 𝗔𝗜 𝗶𝗻 𝘁𝗵𝗲𝗶𝗿 𝘀𝘆𝘀𝘁𝗲𝗺?

𝘞𝘦 𝘩𝘢𝘷𝘦 𝘩𝘢𝘥 𝘵𝘰 𝘱𝘪𝘷𝘰𝘵 𝘪𝘯 𝘩𝘰𝘸 𝘸𝘦 𝘥𝘦𝘷𝘦𝘭𝘰𝘱 𝘴𝘺𝘴𝘵𝘦𝘮𝘴 𝘤𝘰𝘮𝘱𝘭𝘦𝘵𝘦𝘭𝘺. 𝘍𝘰𝘳 𝘦𝘹𝘢𝘮𝘱𝘭𝘦, 𝘥𝘶𝘳𝘪𝘯𝘨 𝘰𝘶𝘳 𝘔𝘰𝘯𝘦𝘺𝘞𝘰𝘳𝘬𝘴 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘪𝘯𝘨/𝘌𝘙𝘗 𝘪𝘯𝘵𝘦𝘨𝘳𝘢𝘵𝘪𝘰𝘯, 𝘸𝘦 𝘴𝘦𝘵 𝘰𝘶𝘵 𝘵𝘰 𝘣𝘶𝘪𝘭𝘥 𝘢𝘯 𝘈𝘐-𝘧𝘪𝘳𝘴𝘵 𝘈𝘗𝘐 𝘢𝘯𝘥 𝘭𝘦𝘢𝘳𝘯𝘦𝘥 𝘴𝘰𝘮𝘦 𝘦𝘹𝘱𝘦𝘯𝘴𝘪𝘷𝘦 𝘭𝘦𝘴𝘴𝘰𝘯𝘴. 𝘞𝘦 𝘩𝘢𝘷𝘦 𝘩𝘢𝘥 𝘵𝘰 𝘱𝘪𝘷𝘰𝘵 𝘵𝘰 𝘢 "𝘤𝘢𝘯𝘰𝘯𝘪𝘤𝘢𝘭-𝘧𝘪𝘳𝘴𝘵" 𝘢𝘱𝘱𝘳𝘰𝘢𝘤𝘩. 𝘐𝘯𝘴𝘵𝘦𝘢𝘥 𝘰𝘧 𝘣𝘶𝘪𝘭𝘥𝘪𝘯𝘨 𝘢𝘯𝘰𝘵𝘩𝘦𝘳 𝘈𝘗𝘐 𝘵𝘩𝘢𝘵 𝘴𝘩𝘶𝘵𝘵𝘭𝘦𝘴 𝘥𝘢𝘵𝘢 𝘢𝘳𝘰𝘶𝘯𝘥, 𝘸𝘦'𝘷𝘦 𝘤𝘳𝘦𝘢𝘵𝘦𝘥  44 𝙨𝙥𝙚𝙘𝙞𝙖𝙡𝙞𝙨𝙚𝙙 𝙈𝘾𝙋 𝙩𝙤𝙤𝙡𝙨 𝘵𝘩𝘢𝘵 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘪𝘯𝘨 𝘥𝘰𝘮𝘢𝘪𝘯 𝘬𝘯𝘰𝘸𝘭𝘦𝘥𝘨𝘦.

𝘍𝘰𝘳 𝘦𝘹𝘢𝘮𝘱𝘭𝘦, 𝘸𝘩𝘦𝘯 𝘰𝘶𝘳 𝘈𝘐 𝘦𝘯𝘤𝘰𝘶𝘯𝘵𝘦𝘳𝘴 𝘈𝘤𝘤𝘰𝘶𝘯𝘵𝘛𝘺𝘱𝘦.𝘊𝘜𝘙𝘙𝘌𝘕𝘛\_𝘈𝘚𝘚𝘌𝘛, 𝘪𝘵 𝘥𝘰𝘦𝘴𝘯'𝘵 𝘫𝘶𝘴𝘵 𝘴𝘦𝘦 𝘢 𝘴𝘵𝘳𝘪𝘯𝘨; 𝘪𝘵 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥𝘴 𝘵𝘩𝘪𝘴 𝘳𝘦𝘱𝘳𝘦𝘴𝘦𝘯𝘵𝘴 𝘭𝘪𝘲𝘶𝘪𝘥 𝘳𝘦𝘴𝘰𝘶𝘳𝘤𝘦𝘴 𝘸𝘪𝘵𝘩 𝘴𝘱𝘦𝘤𝘪𝘧𝘪𝘤 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴 𝘪𝘮𝘱𝘭𝘪𝘤𝘢𝘵𝘪𝘰𝘯𝘴. 𝘞𝘦'𝘷𝘦 𝘦𝘹𝘵𝘳𝘢𝘤𝘵𝘦𝘥 30+ 𝘺𝘦𝘢𝘳𝘴 𝘰𝘧 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘪𝘯𝘨 𝘥𝘰𝘮𝘢𝘪𝘯 𝘬𝘯𝘰𝘸𝘭𝘦𝘥𝘨𝘦 𝘪𝘯𝘵𝘰 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘛𝘺𝘱𝘦𝘚𝘤𝘳𝘪𝘱𝘵 𝘥𝘦𝘧𝘪𝘯𝘪𝘵𝘪𝘰𝘯𝘴 𝘵𝘩𝘢𝘵 𝘤𝘢𝘳𝘳𝘺 𝘤𝘰𝘯𝘵𝘦𝘹𝘵, 𝘯𝘰𝘵 𝘫𝘶𝘴𝘵 𝘥𝘢𝘵𝘢.

𝘛𝘩𝘦 𝘳𝘦𝘴𝘶𝘭𝘵? 𝘖𝘶𝘳 𝘈𝘐 𝘤𝘢𝘯 𝘩𝘢𝘷𝘦 𝘤𝘰𝘯𝘷𝘦𝘳𝘴𝘢𝘵𝘪𝘰𝘯𝘴 𝘭𝘪𝘬𝘦 "𝘚𝘩𝘰𝘸 𝘮𝘦 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘴 𝘵𝘩𝘢𝘵 𝘢𝘧𝘧𝘦𝘤𝘵 𝘤𝘢𝘴𝘩 𝘧𝘭𝘰𝘸" 𝘳𝘢𝘵𝘩𝘦𝘳 𝘵𝘩𝘢𝘯 𝘳𝘦𝘲𝘶𝘪𝘳𝘪𝘯𝘨 𝘵𝘦𝘤𝘩𝘯𝘪𝘤𝘢𝘭 𝘲𝘶𝘦𝘳𝘪𝘦𝘴 𝘭𝘪𝘬𝘦 "𝘚𝘌𝘓𝘌𝘊𝘛 \* 𝘞𝘏𝘌𝘙𝘌 𝘢𝘤𝘤𝘰𝘶𝘯𝘵\_𝘵𝘺𝘱𝘦 \= '𝘊𝘈'".

* 𝗪𝗵𝗮𝘁 𝗶𝘀 𝘁𝗵𝗲 𝗯𝗶𝗴𝗴𝗲𝘀𝘁 𝗰𝗵𝗮𝗹𝗹𝗲𝗻𝗴𝗲 𝘆𝗼𝘂 𝗵𝗮𝘃𝗲 𝗵𝗮𝗱 𝘁𝗼 𝗼𝘃𝗲𝗿𝗰𝗼𝗺𝗲?

𝘖𝘶𝘳 𝘣𝘪𝘨𝘨𝘦𝘴𝘵 𝘤𝘩𝘢𝘭𝘭𝘦𝘯𝘨𝘦 𝘸𝘢𝘴 𝘯𝘰𝘵 𝘳𝘦𝘢𝘭𝘪𝘴𝘪𝘯𝘨 𝘦𝘢𝘳𝘭𝘪𝘦𝘳 𝘵𝘩𝘢𝘵 𝘸𝘦 𝘩𝘢𝘥 𝘵𝘰 𝘳𝘦𝘤𝘰𝘯𝘴𝘪𝘥𝘦𝘳 𝘰𝘶𝘳 𝘢𝘱𝘱𝘳𝘰𝘢𝘤𝘩 𝘵𝘰 𝘣𝘶𝘪𝘭𝘥𝘪𝘯𝘨 𝘴𝘰𝘧𝘵𝘸𝘢𝘳𝘦 𝘧𝘰𝘳 𝘢𝘯 𝘈𝘐-𝘧𝘪𝘳𝘴𝘵 𝘢𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 𝘤𝘰𝘮𝘱𝘭𝘦𝘵𝘦𝘭𝘺. 𝘞𝘦 𝘪𝘯𝘪𝘵𝘪𝘢𝘭𝘭𝘺 𝘵𝘳𝘪𝘦𝘥 𝘵𝘩𝘦 𝘵𝘳𝘢𝘥𝘪𝘵𝘪𝘰𝘯𝘢𝘭 𝘳𝘰𝘶𝘵𝘦—𝘣𝘶𝘪𝘭𝘥𝘪𝘯𝘨 𝘈𝘗𝘐𝘴 𝘢𝘯𝘥 𝘵𝘩𝘦𝘯 𝘸𝘳𝘪𝘵𝘪𝘯𝘨 𝘦𝘭𝘢𝘣𝘰𝘳𝘢𝘵𝘦 𝘤𝘰𝘯𝘵𝘦𝘹𝘵-𝘴𝘱𝘦𝘤𝘪𝘧𝘪𝘤 𝘱𝘳𝘰𝘮𝘱𝘵𝘴 𝘵𝘰 𝘩𝘦𝘭𝘱 𝘈𝘐 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥 𝘰𝘶𝘳 𝘥𝘢𝘵𝘢. 𝘞𝘦 𝘲𝘶𝘪𝘤𝘬𝘭𝘺 𝘥𝘪𝘴𝘤𝘰𝘷𝘦𝘳𝘦𝘥 𝘸𝘦 𝘸𝘦𝘳𝘦 𝘣𝘶𝘳𝘯𝘪𝘯𝘨 𝘵𝘰𝘬𝘦𝘯𝘴 𝘶𝘱 𝘵𝘩𝘦 𝘸𝘳𝘰𝘯𝘨 𝘵𝘳𝘦𝘦, 𝘴𝘱𝘦𝘯𝘥𝘪𝘯𝘨 𝘦𝘯𝘰𝘳𝘮𝘰𝘶𝘴 𝘦𝘧𝘧𝘰𝘳𝘵 𝘰𝘯 𝘱𝘳𝘰𝘮𝘱𝘵 𝘦𝘯𝘨𝘪𝘯𝘦𝘦𝘳𝘪𝘯𝘨 𝘵𝘰 𝘤𝘰𝘮𝘱𝘦𝘯𝘴𝘢𝘵𝘦 𝘧𝘰𝘳 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤𝘢𝘭𝘭𝘺 𝘱𝘰𝘰𝘳 𝘥𝘢𝘵𝘢 𝘴𝘵𝘳𝘶𝘤𝘵𝘶𝘳𝘦𝘴.

𝘉𝘶𝘵 𝘵𝘩𝘦 𝘥𝘦𝘦𝘱𝘦𝘳 𝘤𝘩𝘢𝘭𝘭𝘦𝘯𝘨𝘦 𝘸𝘢𝘴 𝘰𝘯𝘵𝘰𝘭𝘰𝘨𝘪𝘤𝘢𝘭 𝘮𝘢𝘱𝘱𝘪𝘯𝘨. 𝘔𝘰𝘯𝘦𝘺𝘞𝘰𝘳𝘬𝘴 𝘩𝘢𝘴 𝘧𝘪𝘦𝘭𝘥𝘴 𝘭𝘪𝘬𝘦 𝘛𝘺𝘱𝘦 𝘵𝘩𝘢𝘵 𝘤𝘰𝘶𝘭𝘥 𝘮𝘦𝘢𝘯 𝘢𝘤𝘤𝘰𝘶𝘯𝘵 𝘵𝘺𝘱𝘦, 𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯 𝘵𝘺𝘱𝘦, 𝘰𝘳 𝘤𝘰𝘯𝘵𝘢𝘤𝘵 𝘵𝘺𝘱𝘦, 𝘥𝘦𝘱𝘦𝘯𝘥𝘪𝘯𝘨 𝘰𝘯 𝘤𝘰𝘯𝘵𝘦𝘹𝘵. 𝘞𝘦 𝘩𝘢𝘥 𝘵𝘰 𝘴𝘺𝘴𝘵𝘦𝘮𝘢𝘵𝘪𝘤𝘢𝘭𝘭𝘺 𝘦𝘹𝘵𝘳𝘢𝘤𝘵 𝘢𝘯𝘥 𝘤𝘰𝘥𝘪𝘧𝘺 𝘵𝘩𝘳𝘦𝘦 𝘥𝘦𝘤𝘢𝘥𝘦𝘴 𝘰𝘧 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘪𝘯𝘨 𝘥𝘰𝘮𝘢𝘪𝘯 𝘬𝘯𝘰𝘸𝘭𝘦𝘥𝘨𝘦 𝘪𝘯𝘵𝘰 𝘮𝘢𝘤𝘩𝘪𝘯𝘦-𝘳𝘦𝘢𝘥𝘢𝘣𝘭𝘦 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘥𝘦𝘧𝘪𝘯𝘪𝘵𝘪𝘰𝘯𝘴, 𝘰𝘳𝘪𝘨𝘪𝘯𝘢𝘭𝘭𝘺 𝘴𝘤𝘢𝘵𝘵𝘦𝘳𝘦𝘥 𝘪𝘯 𝘢 𝘩𝘶𝘮𝘢𝘯-𝘧𝘳𝘪𝘦𝘯𝘥𝘭𝘺, 𝘨𝘭𝘰𝘳𝘪𝘰𝘶𝘴 800-𝘱𝘢𝘨𝘦 𝘔𝘰𝘯𝘦𝘺𝘞𝘰𝘳𝘬𝘴 𝘮𝘢𝘯𝘶𝘢𝘭.

𝘐𝘵 𝘧𝘰𝘳𝘤𝘦𝘥 𝘶𝘴 𝘵𝘰 𝘢𝘴𝘬: 𝘋𝘰𝘦𝘴 𝘵𝘩𝘪𝘴 𝘧𝘪𝘦𝘭𝘥 𝘦𝘹𝘪𝘴𝘵 𝘣𝘦𝘤𝘢𝘶𝘴𝘦 𝘰𝘧 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘪𝘯𝘨 𝘱𝘳𝘪𝘯𝘤𝘪𝘱𝘭𝘦𝘴, 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴 𝘭𝘰𝘨𝘪𝘤, 𝘰𝘳 𝘫𝘶𝘴𝘵 𝘩𝘪𝘴𝘵𝘰𝘳𝘪𝘤𝘢𝘭 𝘢𝘤𝘤𝘪𝘥𝘦𝘯𝘵? 𝘛𝘩𝘢𝘵 𝘲𝘶𝘦𝘴𝘵𝘪𝘰𝘯𝘪𝘯𝘨 𝘳𝘦𝘷𝘦𝘢𝘭𝘦𝘥 𝘸𝘩𝘦𝘳𝘦 𝘵𝘩𝘦 𝘳𝘦𝘢𝘭 𝘪𝘯𝘵𝘦𝘭𝘭𝘪𝘨𝘦𝘯𝘤𝘦 𝘭𝘪𝘷𝘦𝘥—𝘢𝘯𝘥 𝘪𝘵 𝘸𝘢𝘴𝘯'𝘵 𝘪𝘯 𝘰𝘶𝘳 𝘥𝘢𝘵𝘢𝘣𝘢𝘴𝘦𝘴.

* 𝗪𝗵𝗮𝘁 𝗯𝗲𝗻𝗲𝗳𝗶𝘁 𝗱𝗼 𝘆𝗼𝘂 𝗵𝗼𝗽𝗲 𝘁𝗼 𝗿𝗲𝗮𝗽 𝗳𝗿𝗼𝗺 𝘁𝗵𝗶𝘀 𝗶𝗻𝘁𝗲𝗴𝗿𝗮𝘁𝗶𝗼𝗻?

𝗗𝗲𝗺𝗼𝗰𝗿𝗮𝘁𝗶𝘀𝗮𝘁𝗶𝗼𝗻 𝗼𝗳 𝗰𝗼𝗺𝗽𝗹𝗲𝘅 𝗮𝗰𝗰𝗼𝘂𝗻𝘁𝗶𝗻𝗴 𝗸𝗻𝗼𝘄𝗹𝗲𝗱𝗴𝗲 𝘛𝘰𝘥𝘢𝘺, 𝘺𝘰𝘶 𝘯𝘦𝘦𝘥 𝘺𝘦𝘢𝘳𝘴 𝘰𝘧 𝘔𝘰𝘯𝘦𝘺𝘞𝘰𝘳𝘬𝘴 𝘵𝘳𝘢𝘪𝘯𝘪𝘯𝘨 𝘵𝘰 𝘯𝘢𝘷𝘪𝘨𝘢𝘵𝘦 𝘪𝘵𝘴 1000+ 𝘧𝘪𝘦𝘭𝘥𝘴 𝘢𝘯𝘥 30+ 𝘵𝘢𝘣𝘭𝘦𝘴. 𝘖𝘶𝘳 𝘈𝘐 𝘤𝘢𝘯 𝘣𝘳𝘪𝘥𝘨𝘦 𝘵𝘩𝘢𝘵 𝘨𝘢𝘱.

𝘐𝘮𝘢𝘨𝘪𝘯𝘦 𝘢𝘴𝘬𝘪𝘯𝘨: "𝘞𝘩𝘺 𝘪𝘴 𝘮𝘺 𝘨𝘳𝘰𝘴𝘴 𝘮𝘢𝘳𝘨𝘪𝘯 𝘥𝘦𝘤𝘭𝘪𝘯𝘪𝘯𝘨?" 𝘢𝘯𝘥 𝘨𝘦𝘵𝘵𝘪𝘯𝘨 𝘤𝘰𝘯𝘵𝘦𝘹𝘵𝘶𝘢𝘭 𝘢𝘯𝘢𝘭𝘺𝘴𝘪𝘴 𝘵𝘩𝘢𝘵 𝘤𝘰𝘯𝘯𝘦𝘤𝘵𝘴 𝘱𝘳𝘰𝘥𝘶𝘤𝘵 𝘤𝘰𝘴𝘵𝘴, 𝘢𝘤𝘤𝘰𝘶𝘯𝘵 𝘤𝘭𝘢𝘴𝘴𝘪𝘧𝘪𝘤𝘢𝘵𝘪𝘰𝘯𝘴, 𝘢𝘯𝘥 𝘵𝘳𝘢𝘯𝘴𝘢𝘤𝘵𝘪𝘰𝘯 𝘱𝘢𝘵𝘵𝘦𝘳𝘯𝘴—𝘯𝘰𝘵 𝘫𝘶𝘴𝘵 𝘯𝘶𝘮𝘣𝘦𝘳𝘴, 𝘣𝘶𝘵 𝘵𝘩𝘦 𝘴𝘵𝘰𝘳𝘺 𝘵𝘩𝘦𝘺 𝘵𝘦𝘭𝘭.

𝘞𝘦'𝘳𝘦 𝘮𝘰𝘷𝘪𝘯𝘨 𝘧𝘳𝘰𝘮 "𝘚𝘩𝘰𝘸 𝘮𝘦 𝘵𝘩𝘦 𝘥𝘢𝘵𝘢" 𝘵𝘰 "𝘏𝘦𝘭𝘱 𝘮𝘦 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥 𝘵𝘩𝘦 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴." 𝘛𝘩𝘢𝘵'𝘴 𝘵𝘩𝘦 𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘤𝘦 𝘣𝘦𝘵𝘸𝘦𝘦𝘯 𝘪𝘯𝘧𝘰𝘳𝘮𝘢𝘵𝘪𝘰𝘯 𝘢𝘯𝘥 𝘪𝘯𝘵𝘦𝘭𝘭𝘪𝘨𝘦𝘯𝘤𝘦.

* 𝗪𝗵𝗮𝘁 𝗱𝗼𝗲𝘀 𝗶𝘁 𝗹𝗼𝗼𝗸 𝗹𝗶𝗸𝗲 𝘄𝗵𝗲𝗻 𝗮 𝘀𝘆𝘀𝘁𝗲𝗺 𝘂𝗻𝗱𝗲𝗿𝘀𝘁𝗮𝗻𝗱𝘀 𝘄𝗵𝘆 𝗮 𝗽𝗶𝗲𝗰𝗲 𝗼𝗳 𝗱𝗮𝘁𝗮 𝗲𝘅𝗶𝘀𝘁𝘀, 𝗻𝗼𝘁 𝗷𝘂𝘀𝘁 𝘄𝗵𝗮𝘁 𝗶𝘁 𝗶𝘀?

𝘛𝘢𝘬𝘦 𝘰𝘶𝘳 𝘗𝘢𝘺𝘮𝘦𝘯𝘵𝘔𝘦𝘵𝘩𝘰𝘥 𝘦𝘯𝘶𝘮. 𝘛𝘳𝘢𝘥𝘪𝘵𝘪𝘰𝘯𝘢𝘭 𝘴𝘺𝘴𝘵𝘦𝘮𝘴 𝘴𝘵𝘰𝘳𝘦 "𝘊𝘊" 𝘢𝘴 𝘢 𝘴𝘵𝘳𝘪𝘯𝘨. 𝘖𝘶𝘳 𝘤𝘢𝘯𝘰𝘯𝘪𝘤𝘢𝘭 𝘰𝘯𝘵𝘰𝘭𝘰𝘨𝘺 𝘬𝘯𝘰𝘸𝘴:

* 𝘗𝘢𝘺𝘮𝘦𝘯𝘵𝘔𝘦𝘵𝘩𝘰𝘥.𝘊𝘙𝘌𝘋𝘐𝘛\_𝘊𝘈𝘙𝘋 𝘩𝘢𝘴 𝘮𝘦𝘳𝘤𝘩𝘢𝘯𝘵 𝘧𝘦𝘦𝘴  
* 𝘐𝘵 𝘢𝘧𝘧𝘦𝘤𝘵𝘴 𝘤𝘢𝘴𝘩 𝘧𝘭𝘰𝘸 𝘵𝘪𝘮𝘪𝘯𝘨 𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘵𝘭𝘺 𝘵𝘩𝘢𝘯 𝘗𝘢𝘺𝘮𝘦𝘯𝘵𝘔𝘦𝘵𝘩𝘰𝘥.𝘊𝘈𝘚𝘏  
* 𝘐𝘵 𝘳𝘦𝘲𝘶𝘪𝘳𝘦𝘴 𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘵 𝘳𝘦𝘤𝘰𝘯𝘤𝘪𝘭𝘪𝘢𝘵𝘪𝘰𝘯 𝘱𝘳𝘰𝘤𝘦𝘴𝘴𝘦𝘴  
* 𝘐𝘵 𝘩𝘢𝘴 𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘵 𝘧𝘳𝘢𝘶𝘥 𝘳𝘪𝘴𝘬 𝘱𝘳𝘰𝘧𝘪𝘭𝘦𝘴

𝘞𝘩𝘦𝘯 𝘈𝘐 𝘦𝘯𝘤𝘰𝘶𝘯𝘵𝘦𝘳𝘴 𝘵𝘩𝘪𝘴 𝘥𝘢𝘵𝘢, 𝘪𝘵 𝘥𝘰𝘦𝘴𝘯'𝘵 𝘫𝘶𝘴𝘵 𝘴𝘦𝘦 𝘱𝘢𝘺𝘮𝘦𝘯𝘵 𝘵𝘺𝘱𝘦—𝘪𝘵 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥𝘴 𝘵𝘩𝘦 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴 𝘪𝘮𝘱𝘭𝘪𝘤𝘢𝘵𝘪𝘰𝘯𝘴, 𝘳𝘦𝘭𝘢𝘵𝘪𝘰𝘯𝘴𝘩𝘪𝘱𝘴, 𝘢𝘯𝘥 𝘤𝘰𝘯𝘴𝘵𝘳𝘢𝘪𝘯𝘵𝘴 𝘵𝘩𝘢𝘵 𝘵𝘩𝘦 𝘱𝘢𝘺𝘮𝘦𝘯𝘵 𝘮𝘦𝘵𝘩𝘰𝘥 𝘤𝘢𝘳𝘳𝘪𝘦𝘴. 𝘛𝘩𝘦 𝘥𝘢𝘵𝘢 𝘣𝘦𝘤𝘰𝘮𝘦𝘴 𝘴𝘦𝘭𝘧-𝘥𝘦𝘴𝘤𝘳𝘪𝘣𝘪𝘯𝘨 𝘢𝘯𝘥 𝘤𝘰𝘯𝘵𝘦𝘹𝘵-𝘢𝘸𝘢𝘳𝘦.

* 𝗛𝗼𝘄 𝗰𝗮𝗻 𝗮 𝗰𝗼𝗺𝗽𝗮𝗻𝘆 𝘁𝗲𝗹𝗹 𝗶𝗳 𝗶𝘁𝘀 𝗰𝘂𝗿𝗿𝗲𝗻𝘁 𝘀𝘁𝗮𝗰𝗸 𝗶𝘀 𝗯𝘂𝗶𝗹𝘁 𝗼𝗻 𝘁𝗵𝗲 “𝗵𝗮𝗹𝗳-𝘁𝗿𝘂𝘁𝗵” 𝗼𝗳 𝗱𝗮𝘁𝗮 𝗯𝗲𝗶𝗻𝗴 𝗷𝘂𝘀𝘁 𝗱𝗮𝘁𝗮? 𝗪𝗵𝗮𝘁 𝗮𝗿𝗲 𝘁𝗵𝗲 𝘀𝗶𝗴𝗻𝘀?

𝘙𝘦𝘥 𝘧𝘭𝘢𝘨𝘴 𝘸𝘦 𝘥𝘪𝘴𝘤𝘰𝘷𝘦𝘳𝘦𝘥:

* 𝘔𝘢𝘨𝘪𝘤 𝘯𝘶𝘮𝘣𝘦𝘳𝘴 𝘦𝘷𝘦𝘳𝘺𝘸𝘩𝘦𝘳𝘦: 𝘚𝘵𝘢𝘵𝘶𝘴 𝘤𝘰𝘥𝘦𝘴 𝘭𝘪𝘬𝘦 1, 2, 3 𝘸𝘪𝘵𝘩 𝘯𝘰 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘮𝘦𝘢𝘯𝘪𝘯𝘨  
* 𝘛𝘳𝘪𝘣𝘢𝘭 𝘬𝘯𝘰𝘸𝘭𝘦𝘥𝘨𝘦 𝘥𝘦𝘱𝘦𝘯𝘥𝘦𝘯𝘤𝘺: 𝘖𝘯𝘭𝘺 𝘑𝘢𝘯𝘦𝘵 𝘬𝘯𝘰𝘸𝘴 𝘸𝘩𝘺 𝘤𝘦𝘳𝘵𝘢𝘪𝘯 𝘧𝘪𝘦𝘭𝘥𝘴 𝘮𝘢𝘵𝘵𝘦𝘳  
* 𝘋𝘰𝘤𝘶𝘮𝘦𝘯𝘵𝘢𝘵𝘪𝘰𝘯 𝘥𝘦𝘣𝘵: 𝘈𝘗𝘐𝘴 𝘵𝘩𝘢𝘵 𝘥𝘦𝘴𝘤𝘳𝘪𝘣𝘦 𝘸𝘩𝘢𝘵 𝘣𝘶𝘵 𝘯𝘦𝘷𝘦𝘳 𝘸𝘩𝘺  
* 𝘈𝘐 𝘤𝘰𝘯𝘧𝘶𝘴𝘪𝘰𝘯: 𝘠𝘰𝘶𝘳 𝘮𝘰𝘥𝘦𝘭𝘴 𝘤𝘢𝘯'𝘵 𝘦𝘹𝘱𝘭𝘢𝘪𝘯 𝘵𝘩𝘦𝘪𝘳 𝘳𝘦𝘢𝘴𝘰𝘯𝘪𝘯𝘨 𝘣𝘦𝘤𝘢𝘶𝘴𝘦 𝘵𝘩𝘦 𝘥𝘢𝘵𝘢 𝘤𝘢𝘯'𝘵 𝘦𝘹𝘱𝘭𝘢𝘪𝘯 𝘪𝘵𝘴𝘦𝘭𝘧

𝘛𝘩𝘦 𝘭𝘪𝘵𝘮𝘶𝘴 𝘵𝘦𝘴𝘵: 𝘊𝘢𝘯 𝘢 𝘯𝘦𝘸 𝘵𝘦𝘢𝘮 𝘮𝘦𝘮𝘣𝘦𝘳 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥 𝘺𝘰𝘶𝘳 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴 𝘭𝘰𝘨𝘪𝘤 𝘫𝘶𝘴𝘵 𝘣𝘺 𝘳𝘦𝘢𝘥𝘪𝘯𝘨 𝘺𝘰𝘶𝘳 𝘥𝘢𝘵𝘢 𝘴𝘵𝘳𝘶𝘤𝘵𝘶𝘳𝘦𝘴? 𝘐𝘧 𝘯𝘰𝘵, 𝘺𝘰𝘶𝘳 𝘈𝘐 𝘤𝘦𝘳𝘵𝘢𝘪𝘯𝘭𝘺 𝘤𝘢𝘯'𝘵.

* 𝗛𝗼𝘄 𝘀𝗵𝗼𝘂𝗹𝗱 𝘁𝗲𝗮𝗺𝘀 𝘀𝗵𝗶𝗳𝘁 𝘁𝗵𝗲𝗶𝗿 𝘁𝗵𝗶𝗻𝗸𝗶𝗻𝗴 𝘄𝗵𝗲𝗻 𝗮𝗽𝗽𝗿𝗼𝗮𝗰𝗵𝗶𝗻𝗴 𝗔𝗜-𝗳𝗶𝗿𝘀𝘁 𝗮𝗿𝗰𝗵𝗶𝘁𝗲𝗰𝘁𝘂𝗿𝗲?

𝗦𝘁𝗮𝗿𝘁 𝘄𝗶𝘁𝗵 𝗱𝗼𝗺𝗮𝗶𝗻 𝗺𝗼𝗱𝗲𝗹𝗹𝗶𝗻𝗴, 𝗻𝗼𝘁 𝗱𝗮𝘁𝗮 𝗺𝗼𝗱𝗲𝗹𝗹𝗶𝗻𝗴.𝘞𝘦 𝘣𝘦𝘨𝘢𝘯 𝘣𝘺 𝘢𝘴𝘬𝘪𝘯𝘨: "𝘏𝘰𝘸 𝘥𝘰𝘦𝘴 𝘢𝘯 𝘢𝘤𝘤𝘰𝘶𝘯𝘵𝘢𝘯𝘵 𝘵𝘩𝘪𝘯𝘬 𝘢𝘣𝘰𝘶𝘵 𝘵𝘩𝘪𝘴 𝘪𝘯𝘧𝘰𝘳𝘮𝘢𝘵𝘪𝘰𝘯?" 𝘯𝘰𝘵 "𝘏𝘰𝘸 𝘥𝘰 𝘸𝘦 𝘴𝘵𝘰𝘳𝘦 𝘵𝘩𝘪𝘴 𝘥𝘢𝘵𝘢?"

𝘛𝘳𝘢𝘥𝘪𝘵𝘪𝘰𝘯𝘢𝘭 𝘧𝘭𝘰𝘸: 𝘋𝘢𝘵𝘢𝘣𝘢𝘴𝘦 → 𝘈𝘗𝘐 → 𝘐𝘯𝘵𝘦𝘳𝘧𝘢𝘤𝘦 → 𝘈𝘐 (𝘣𝘰𝘭𝘵𝘦𝘥 𝘰𝘯)

𝘖𝘶𝘳 𝘢𝘱𝘱𝘳𝘰𝘢𝘤𝘩: 𝘋𝘰𝘮𝘢𝘪𝘯 𝘜𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥𝘪𝘯𝘨 → 𝘚𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘔𝘰𝘥𝘦𝘭𝘴 → 𝘊𝘰𝘯𝘵𝘦𝘹𝘵-𝘈𝘸𝘢𝘳𝘦 𝘈𝘗𝘐𝘴 → 𝘈𝘐-𝘕𝘢𝘵𝘪𝘷𝘦 𝘛𝘰𝘰𝘭𝘴

𝘗𝘳𝘢𝘤𝘵𝘪𝘤𝘢𝘭 𝘴𝘩𝘪𝘧𝘵𝘴:

* 𝘙𝘦𝘱𝘭𝘢𝘤𝘦 𝘱𝘳𝘪𝘮𝘪𝘵𝘪𝘷𝘦 𝘵𝘺𝘱𝘦𝘴 𝘸𝘪𝘵𝘩 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘦𝘯𝘶𝘮𝘴  
* 𝘉𝘶𝘪𝘭𝘥 𝘤𝘢𝘯𝘰𝘯𝘪𝘤𝘢𝘭 𝘰𝘯𝘵𝘰𝘭𝘰𝘨𝘪𝘦𝘴 𝘣𝘦𝘧𝘰𝘳𝘦 𝘴𝘤𝘩𝘦𝘮𝘢𝘴  
* 𝘋𝘦𝘴𝘪𝘨𝘯 𝘧𝘰𝘳 𝘈𝘐 𝘤𝘰𝘮𝘱𝘳𝘦𝘩𝘦𝘯𝘴𝘪𝘰𝘯, 𝘯𝘰𝘵 𝘫𝘶𝘴𝘵 𝘩𝘶𝘮𝘢𝘯 𝘤𝘰𝘯𝘴𝘶𝘮𝘱𝘵𝘪𝘰𝘯  
* 𝘛𝘩𝘪𝘯𝘬 𝘳𝘦𝘭𝘢𝘵𝘪𝘰𝘯𝘴𝘩𝘪𝘱𝘴 𝘢𝘯𝘥 𝘮𝘦𝘢𝘯𝘪𝘯𝘨 𝘧𝘪𝘳𝘴𝘵, 𝘴𝘵𝘰𝘳𝘢𝘨𝘦 𝘰𝘱𝘵𝘪𝘮𝘪𝘴𝘢𝘵𝘪𝘰𝘯 𝘴𝘦𝘤𝘰𝘯𝘥  
    
* 𝗗𝗼 𝘆𝗼𝘂 𝘁𝗵𝗶𝗻𝗸 𝗺𝗼𝘀𝘁 𝗰𝗼𝗺𝗽𝗮𝗻𝗶𝗲𝘀 𝘄𝗶𝗹𝗹 𝗲𝘃𝗲𝗿 𝗯𝗲 𝗿𝗲𝗮𝗱𝘆 𝗳𝗼𝗿 𝗔𝗜 𝘁𝗵𝗮𝘁’𝘀 𝘁𝗿𝘂𝗹𝘆 𝗶𝗻𝘁𝗲𝗹𝗹𝗶𝗴𝗲𝗻𝘁, 𝗼𝗿 𝘄𝗶𝗹𝗹 𝘄𝗲 𝗮𝗹𝘄𝗮𝘆𝘀 𝗯𝗲 𝗿𝗲𝘁𝗿𝗼𝗳𝗶𝘁𝘁𝗶𝗻𝗴 𝗺𝗲𝗮𝗻𝗶𝗻𝗴 𝗼𝗻𝘁𝗼 𝗹𝗲𝗴𝗮𝗰𝘆 𝘀𝘆𝘀𝘁𝗲𝗺𝘀?

𝘙𝘦𝘵𝘳𝘰𝘧𝘪𝘵𝘵𝘪𝘯𝘨 𝘤𝘢𝘯 𝘸𝘰𝘳𝘬 𝘧𝘰𝘳 𝘣𝘢𝘴𝘪𝘤 𝘢𝘶𝘵𝘰𝘮𝘢𝘵𝘪𝘰𝘯—𝘤𝘩𝘢𝘵𝘣𝘰𝘵𝘴 𝘳𝘦𝘢𝘥𝘪𝘯𝘨 𝘍𝘈𝘘𝘴, 𝘴𝘪𝘮𝘱𝘭𝘦 𝘥𝘢𝘵𝘢 𝘲𝘶𝘦𝘳𝘪𝘦𝘴. 𝘉𝘶𝘵 𝘵𝘳𝘢𝘯𝘴𝘧𝘰𝘳𝘮𝘢𝘵𝘪𝘷𝘦 𝘈𝘐 𝘳𝘦𝘲𝘶𝘪𝘳𝘦𝘴 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘧𝘰𝘶𝘯𝘥𝘢𝘵𝘪𝘰𝘯𝘴. 𝘠𝘰𝘶 𝘤𝘢𝘯'𝘵 𝘣𝘰𝘭𝘵 𝘮𝘦𝘢𝘯𝘪𝘯𝘨 𝘰𝘯𝘵𝘰 𝘴𝘺𝘴𝘵𝘦𝘮𝘴 𝘥𝘦𝘴𝘪𝘨𝘯𝘦𝘥 𝘢𝘳𝘰𝘶𝘯𝘥 𝘮𝘦𝘢𝘯𝘪𝘯𝘨𝘭𝘦𝘴𝘴 𝘪𝘥𝘦𝘯𝘵𝘪𝘧𝘪𝘦𝘳𝘴.

𝘛𝘩𝘦 𝘤𝘰𝘮𝘱𝘦𝘵𝘪𝘵𝘪𝘷𝘦 𝘢𝘥𝘷𝘢𝘯𝘵𝘢𝘨𝘦 𝘣𝘦𝘭𝘰𝘯𝘨𝘴 𝘵𝘰 𝘰𝘳𝘨𝘢𝘯𝘪𝘴𝘢𝘵𝘪𝘰𝘯𝘴 𝘸𝘪𝘭𝘭𝘪𝘯𝘨 𝘵𝘰 𝘳𝘦𝘣𝘶𝘪𝘭𝘥 𝘵𝘩𝘦𝘪𝘳 𝘪𝘯𝘧𝘰𝘳𝘮𝘢𝘵𝘪𝘰𝘯 𝘢𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦 𝘢𝘳𝘰𝘶𝘯𝘥 𝘮𝘦𝘢𝘯𝘪𝘯𝘨. 𝘛𝘩𝘰𝘴𝘦 𝘸𝘩𝘰 𝘥𝘰 𝘸𝘪𝘭𝘭 𝘩𝘢𝘷𝘦 𝘈𝘐 𝘵𝘩𝘢𝘵 𝘵𝘳𝘶𝘭𝘺 𝘶𝘯𝘥𝘦𝘳𝘴𝘵𝘢𝘯𝘥𝘴 𝘵𝘩𝘦𝘪𝘳 𝘣𝘶𝘴𝘪𝘯𝘦𝘴𝘴. 𝘛𝘩𝘰𝘴𝘦 𝘸𝘩𝘰 𝘥𝘰𝘯'𝘵 𝘸𝘪𝘭𝘭 𝘩𝘢𝘷𝘦 𝘷𝘦𝘳𝘺 𝘦𝘹𝘱𝘦𝘯𝘴𝘪𝘷𝘦 𝘥𝘢𝘵𝘢 𝘳𝘦𝘵𝘳𝘪𝘦𝘷𝘦𝘳𝘴.

𝘖𝘶𝘳 𝘔𝘰𝘯𝘦𝘺𝘞𝘰𝘳𝘬𝘴 𝘱𝘳𝘰𝘫𝘦𝘤𝘵 𝘱𝘳𝘰𝘷𝘦𝘴 𝘪𝘵'𝘴 𝘱𝘰𝘴𝘴𝘪𝘣𝘭𝘦—𝘣𝘶𝘵 𝘪𝘵 𝘳𝘦𝘲𝘶𝘪𝘳𝘦𝘴 𝘵𝘳𝘦𝘢𝘵𝘪𝘯𝘨 𝘴𝘦𝘮𝘢𝘯𝘵𝘪𝘤 𝘥𝘦𝘴𝘪𝘨𝘯 𝘢𝘴 𝘴𝘦𝘳𝘪𝘰𝘶𝘴𝘭𝘺 𝘢𝘴 𝘵𝘦𝘤𝘩𝘯𝘪𝘤𝘢𝘭 𝘢𝘳𝘤𝘩𝘪𝘵𝘦𝘤𝘵𝘶𝘳𝘦. 𝘛𝘩𝘦 𝘤𝘰𝘮𝘱𝘢𝘯𝘪𝘦𝘴 𝘵𝘩𝘢𝘵 𝘨𝘦𝘵 𝘵𝘩𝘪𝘴 𝘳𝘪𝘨𝘩𝘵 𝘸𝘰𝘯'𝘵 𝘫𝘶𝘴𝘵 𝘩𝘢𝘷𝘦 𝘣𝘦𝘵𝘵𝘦𝘳 𝘈𝘐; 𝘵𝘩𝘦𝘺'𝘭𝘭 𝘩𝘢𝘷𝘦 𝘈𝘐-𝘯𝘢𝘵𝘪𝘷𝘦 𝘤𝘰𝘮𝘱𝘦𝘵𝘪𝘵𝘪𝘷𝘦 𝘢𝘥𝘷𝘢𝘯𝘵𝘢𝘨𝘦𝘴 𝘵𝘩𝘢𝘵 𝘢𝘳𝘦 𝘪𝘮𝘱𝘰𝘴𝘴𝘪𝘣𝘭𝘦 𝘵𝘰 𝘳𝘦𝘱𝘭𝘪𝘤𝘢𝘵𝘦 𝘸𝘪𝘵𝘩 𝘭𝘦𝘨𝘢𝘤𝘺 𝘳𝘦𝘵𝘳𝘰𝘧𝘪𝘵𝘴.

Got a question for Hardy? Drop us a message; we’re always keen to continue the conversation.

**\#AIForBusiness \#ArtificialIntelligence \#DigitalTransformation \#AgileworksAI**